#Exploring the performance of various ml models for binary classificaion tasks
üöÄ Exploring Machine Learning Model Performance for Binary Classification
This project, conducted under the guidance of Professor Bapuji Kanaparthi, focuses on evaluating the performance of six different machine learning models for a binary classification task using customer response data. The project involved comprehensive data preprocessing, feature engineering, exploratory data analysis (EDA), model training, and a detailed comparison of key evaluation metrics.

üéØ Project Goal
The primary goal of this project was to identify the most effective machine learning model for predicting customer responses based on the provided dataset, while also demonstrating the impact of robust data preprocessing and feature engineering techniques.

üõ†Ô∏è Technologies Used
Python
Pandas (for data manipulation)
NumPy (for numerical operations)
Scikit-learn (for machine learning models and evaluation metrics)
Matplotlib (for data visualization)
Seaborn (for enhanced data visualization)
üìä Dataset
The project utilizes customer response data for a binary classification task. Details about the dataset's features and target variable can be found within the Jupyter notebooks in this repository.

‚öôÔ∏è Project Workflow
The project followed a structured approach, encompassing the following key stages:

1. Data Preprocessing & Feature Engineering
Categorical Variable Mapping: Categorical features such as gender, employment status, and marital status were mapped into binary numerical values to ensure compatibility with machine learning models.
New Feature Creation: A significant aspect of this stage was the introduction of the Income-to-Family-Size Ratio. This new feature provides valuable insights into financial stability by normalizing income with respect to family size.
Missing Value Handling: Thorough procedures were implemented to address and impute any missing values, ensuring a clean and complete dataset for modeling.
2. Exploratory Data Analysis (EDA)
Correlation Analysis: Heatmaps were utilized to visualize the correlations between various numerical features, helping to understand relationships and potential multicollinearity.
Behavioral Insights: Scatter plots and pairwise comparisons were employed to explore customer behavior patterns, highlighting factors that influence customer responses.
3. Model Training & Evaluation
Six popular machine learning models were trained and evaluated on the preprocessed dataset:

Logistic Regression
Decision Tree
Random Forest
Support Vector Machine (SVM)
K-Nearest Neighbors (KNN)
Gradient Boosting
The performance of each model was assessed using the following key metrics:

Accuracy: The overall proportion of correct predictions.
Precision: The ratio of correctly predicted positive observations to the total predicted positives.
Recall: The ratio of correctly predicted positive observations to all actual positives.
F1-Score: The harmonic mean of Precision and Recall, providing a balanced measure.
ROC-AUC (Receiver Operating Characteristic - Area Under Curve): A measure of the model's ability to distinguish between the positive and negative classes.
4. Results & Visualizations
The project's findings indicate that Gradient Boosting emerged as the top-performing model, demonstrating superior ability to capture complex patterns within the data while effectively mitigating overfitting. SVM also showed strong performance.

Key visualizations generated to support the findings include:

Bar Plots: Comparing Accuracy, Precision, Recall, F1-Score, and ROC-AUC across all evaluated models.
Confusion Matrices: Providing a detailed breakdown of true positives, true negatives, false positives, and false negatives for each model.
ROC Curves: Illustrating the trade-off between the true positive rate and the false positive rate, with Gradient Boosting's curve showcasing its exceptional performance.
